{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T05:39:53.348806Z",
     "start_time": "2018-05-15T05:39:53.345777Z"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T07:25:40.937012Z",
     "start_time": "2018-05-15T07:25:29.984509Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T07:25:40.945018Z",
     "start_time": "2018-05-15T07:25:40.939016Z"
    }
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "text_columns = \"description\"\n",
    "# Supported datasets:\n",
    "# summary\n",
    "# description\n",
    "\n",
    "# Output\n",
    "column_to_predict = \"urgency\"\n",
    "# Supported datasets:\n",
    "# impact\n",
    "# urgency\n",
    "\n",
    "# Classifier\n",
    "classifier = \"SVM\"\n",
    "# Supported algorithms:\n",
    "# DT\n",
    "# NB\n",
    "# SVM\n",
    "\n",
    "# Removes stop words from processed text\n",
    "remove_stop_words = True\n",
    "stop_words_lang = 'english'\n",
    "\n",
    "# Word stemming using NLTK\n",
    "use_stemming = False\n",
    "\n",
    "# fit_prior: whether to learn class prior probabilities or not.\n",
    "# If false, a uniform prior will be used.\n",
    "if use_stemming:\n",
    "    fit_prior = False\n",
    "else:\n",
    "    fit_prior = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T07:25:41.218329Z",
     "start_time": "2018-05-15T07:25:40.947014Z"
    }
   },
   "outputs": [],
   "source": [
    "dfTickets = pd.read_csv(\n",
    "    './dataset/tickets_1.csv',\n",
    "    engine='python',\n",
    "    dtype=str\n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn Strings into Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>impact</th>\n",
       "      <th>urgency</th>\n",
       "      <th>priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"back to top\" button is on the wrong place</td>\n",
       "      <td>!image-2019-01-23-17-03-59-735.png!</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"code master maintenance\" link is not working</td>\n",
       "      <td>see attached screenshot.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"x\" should not be there</td>\n",
       "      <td>see attached screenshot.</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(next phase) missing content in form but submi...</td>\n",
       "      <td>there is no form appear in this services, howe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(phase 2) code maintenance - missing 'effectiv...</td>\n",
       "      <td>after *order* field there is should be '*effec...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>validation message for every field</td>\n",
       "      <td>please provide the error message for every man...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>wrong lov for relationship</td>\n",
       "      <td>there is no \"others\" option under \"i am the de...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>wrong error message</td>\n",
       "      <td>please correct the below error message\\n\\n!ret...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>â€�view allâ€� button is not working</td>\n",
       "      <td>active application service:â \\n\\n!image-2019-0...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>â€�youâ€™ll needâ€� and â€œyou should knowâ€� ...</td>\n",
       "      <td>!image-2019-01-04-16-31-14-648.png!</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1576 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                summary  \\\n",
       "0            \"back to top\" button is on the wrong place   \n",
       "1         \"code master maintenance\" link is not working   \n",
       "2                               \"x\" should not be there   \n",
       "3     (next phase) missing content in form but submi...   \n",
       "4     (phase 2) code maintenance - missing 'effectiv...   \n",
       "...                                                 ...   \n",
       "1571                 validation message for every field   \n",
       "1572                         wrong lov for relationship   \n",
       "1573                                wrong error message   \n",
       "1574               â€�view allâ€� button is not working   \n",
       "1575  â€�youâ€™ll needâ€� and â€œyou should knowâ€� ...   \n",
       "\n",
       "                                            description impact urgency  \\\n",
       "0                   !image-2019-01-23-17-03-59-735.png!      3       3   \n",
       "1                              see attached screenshot.      2       1   \n",
       "2                              see attached screenshot.      3       3   \n",
       "3     there is no form appear in this services, howe...      1       1   \n",
       "4     after *order* field there is should be '*effec...      1       3   \n",
       "...                                                 ...    ...     ...   \n",
       "1571  please provide the error message for every man...      3       3   \n",
       "1572  there is no \"others\" option under \"i am the de...      2       3   \n",
       "1573  please correct the below error message\\n\\n!ret...      3       3   \n",
       "1574  active application service:â \\n\\n!image-2019-0...      3       3   \n",
       "1575                !image-2019-01-04-16-31-14-648.png!      3       3   \n",
       "\n",
       "     priority  \n",
       "0           3  \n",
       "1           2  \n",
       "2           3  \n",
       "3           1  \n",
       "4           1  \n",
       "...       ...  \n",
       "1571        3  \n",
       "1572        2  \n",
       "1573        3  \n",
       "1574        3  \n",
       "1575        3  \n",
       "\n",
       "[1576 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTickets.apply(lambda x: x.astype(str).str.casefold())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data Set into Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T07:25:41.365785Z",
     "start_time": "2018-05-15T07:25:41.324755Z"
    }
   },
   "outputs": [],
   "source": [
    "labelData = dfTickets[column_to_predict]\n",
    "data = dfTickets[text_columns]\n",
    "\n",
    "# Split dataset into training and testing data with 80:20 ratio\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labelData, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features from the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T07:25:41.374133Z",
     "start_time": "2018-05-15T07:25:41.368126Z"
    }
   },
   "outputs": [],
   "source": [
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T07:25:42.972298Z",
     "start_time": "2018-05-15T07:25:41.377130Z"
    }
   },
   "outputs": [],
   "source": [
    "# Count Vectorizer = tokenizer\n",
    "# Convert a collection of text documents to a matrix of token counts\n",
    "if remove_stop_words:\n",
    "    count_vect = CountVectorizer(stop_words=stop_words_lang)\n",
    "elif use_stemming:\n",
    "    count_vect = StemmedCountVectorizer(stop_words=stop_words_lang)\n",
    "else:\n",
    "    count_vect = CountVectorizer()\n",
    "\n",
    "vectorized_data = count_vect.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T07:25:43.026267Z",
     "start_time": "2018-05-15T07:25:42.975265Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "features = tfidf.fit_transform(vectorized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use A Pipeline to Preprocess Data and Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T07:25:44.786016Z",
     "start_time": "2018-05-15T07:25:43.028264Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if classifier == \"NB\":\n",
    "    clf = Pipeline([\n",
    "        ('vect', count_vect),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('samp',RandomOverSampler()),\n",
    "        ('clf', MultinomialNB(fit_prior=fit_prior))\n",
    "    ])\n",
    "elif classifier == \"DT\":\n",
    "    clf = Pipeline([\n",
    "        ('vect', count_vect),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('samp',RandomOverSampler()),\n",
    "        ('clf', DecisionTreeClassifier())\n",
    "    ])\n",
    "elif classifier == \"SVM\":\n",
    "    clf = Pipeline([\n",
    "        ('vect', count_vect),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('samp',RandomOverSampler()),\n",
    "        ('clf', SVC(kernel='linear'))\n",
    "    ])\n",
    "clf = clf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use GridSearchCV to Find the Best Params Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T07:26:20.271405Z",
     "start_time": "2018-05-15T07:25:44.789019Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__use_idf': (True, False)\n",
    "}\n",
    "# Create GS instance by passing the classifier, parameters and n_jobs=-1 (use multiple cores from user machine)\n",
    "clf = GridSearchCV(clf, parameters, cv=10, n_jobs=-1)\n",
    "clf = clf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T07:26:20.280680Z",
     "start_time": "2018-05-15T07:26:20.274677Z"
    }
   },
   "source": [
    "# Save Model to Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open('./model/'+classifier+'_'+text_columns+'_'+column_to_predict+'_model.pickle',\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T07:26:21.189731Z",
     "start_time": "2018-05-15T07:26:20.282676Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion:\n",
      "[[  7   8  23]\n",
      " [  3  25  41]\n",
      " [ 12  24 173]]\n",
      "Mean: 0.6487341772151899\n"
     ]
    }
   ],
   "source": [
    "# Score and evaluate model on test data using model\n",
    "predicted = clf.predict(test_data)\n",
    "\n",
    "prediction_acc = np.mean(predicted == test_labels)\n",
    "print(\"Confusion:\")\n",
    "print(metrics.confusion_matrix(test_labels, predicted))\n",
    "print(\"Mean: \" + str(prediction_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T07:26:21.684170Z",
     "start_time": "2018-05-15T07:26:21.631088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.18      0.23        38\n",
      "           2       0.44      0.36      0.40        69\n",
      "           3       0.73      0.83      0.78       209\n",
      "\n",
      "    accuracy                           0.65       316\n",
      "   macro avg       0.50      0.46      0.47       316\n",
      "weighted avg       0.62      0.65      0.63       316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, predicted,\n",
    "                            target_names=np.unique(test_labels)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
